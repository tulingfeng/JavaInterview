# Redis篇

## 1.1 redis 中有几种类型 & 各自底层怎么实现的 & 项目中哪个地方用了什么类型，怎么使用的

```text
1.string(字符串)
动态字符串，底层类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配
应用： 缓存用户信息、计数器、共享用户session

2.list(链表)
类似于Java的LinkedList，是链表。插入、删除O(1)，定位O(n)，双向指针，底层是快速链表。
应用：做异步队列，记录帖子的相关文章ID
rpush books python
lpop books

3.hash(字典)
类似于Java的HashMap。区别在于：Redis字典中的值只能是字符串，另外他rehash的方式不同，是渐进性rehash，不会阻塞服务。保留新旧两个hash结构，查询时会同时查询两个hash结构，后续会将旧hash中的数据迁移到新的hash
应用：存储用户信息

4.set(集合)
类似于Java的HashSet，键值对无序、唯一。内部实现相当于一个特殊的字典，字典中所有的value都是一个值NULL
应用：存储某活动中中奖的用户ID

5.zset(有序集合)
类似于Java的SortedSet和HashMap的结合体。
set保证内部value的唯一性，另一方面给每个value赋予一个score，代表这个value的排序权重。
底层是由跳跃列表来实现：采用的层级制，最下层所有元素串起来，往上都是有概率加入的，之所以跳跃，就是内部元素能身兼数职。
应用：可以作热榜。
```

一般项目中就只用了`string`。



## 1.2 redis如何实现分布式锁，zk如何实现分布式锁，两者的区别。如果service还没执行完，分布式锁在redis中已经过期了，怎么解决这种问题

1.redis分布式锁

```text
1.单机版
set lock_key random_value NX PX 5000
random_value: 客户端生成的唯一的字符串，使用随机值的原因，确保当前线程占有的锁不被其他线程释放。
NX：代表键不存在，才对键进行设置操作
PX 5000：设置键的过期时间为5000毫秒

# 解锁 保证解锁操作的原子性，使用LUA脚本实现：
if redis.call('get',KEYS[1]) == ARGV[1] then 
   return redis.call('del',KEYS[1]) 
else
   return 0 
end

但是单机版存在问题：
比如采用的单个master的redis，一个slave节点，配置了哨兵机制。由于redis同步数据是异步的，此时如果master挂了，而slave节点并没有该锁信息。所以：这种方案在redis的master节点挂了后，slave节点变成master节点，客户端发送请求过来此时也可以加锁成功，导致出现同一把锁被两个客户端同时持有。因此要采用集群锁

2.基于RedLock算法，集群中大多数节点加锁成功才算加锁成功。
说明：
1）加锁时，它会向过半节点发送set(key,value,nx=True,ex=xxx)指令，只要过半节点set成功，就认为加锁成功
2）释放锁时，需要向所有节点发送del指令。
RedLock算法需要考虑重试、时钟漂移等很多细节问题，同时因为RedLock需要向多个节点进行读写，性能会下降一些

// 需要多个redisson的实例
RLock lock1 = redissonInstance1.getLock("lock1");
RLock lock2 = redissonInstance2.getLock("lock1");
RLock lock3 = redissonInstance3.getLock("lock1");
RedissonRedLock lock = new RedissonRedLock(lock1, lock2, lock3);
// 同时加锁：lock1 lock2 lock3
// 红锁在大部分节点上加锁成功就算成功。
lock.lock();
...
lock.unlock();
```



2.zookeeper分布式

```text
一般采用curator来实现分布式锁，原理：
1）向zk发起请求，在一个目录(/locks/pd_1_stock)下，创建一个临时节点，也是带有自己客户端的id；
2）如果目录是空的，自己创建出来的节点就是第一个节点，那么加锁成功。
3）第二个客户端请求锁时，也创建一个节点，如果不是第一节点，那么向上一节点加一个watcher监听器。如果上一个节点被删除立马会感知到，然后在判断自己是不是第一节点，如果不是再监听上一级(公平锁实现)。完事后陷入等待，直到获取锁。
4）如果宕机，基于zk的心跳机制，临时节点也会被删除。
```

**分布式锁对比**

```text
redis锁：
其实需要自己不断尝试获取锁，比较耗费性能。而且依赖redis cluster，算法本身争议比较大。

zookeeper锁：
1.获取不到锁，就加个监听器，不需要不断主动尝试获取锁，性能开销小
2.因为zk创建的是临时节点，如果zk挂了，znode就没了，锁自动释放了。但是redis如果获取锁的那个客户端挂了，只能等待超时时间之后才能释放锁。 
```

如果service还没执行完，分布式锁在redis中已经过期了，怎么解决这种问题？

```text
事前：使用Redission来实现分布式锁，Redission提供了一个监控锁的看门狗，作用是在Redission实例被关闭前，不断的延长锁的有效期。Redis分布式锁不要用于较长时间的任务。
事后：可能需要人工介入
```



## 1.3 讲对redis 的了解

```text
Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker。
```

可以用作数据库，缓存，消息队列代理，分布式锁。



## 1.4 redis两种备份的区别

1.RDB 快照持久化（全量备份）

将某一时刻的所有数据保存到一个RDB文件中(压缩的二进制文件)。

以下两个命令可以生产RDB文件：

```text
SAVE
阻塞Redis服务器进程，服务器不能接收任何请求，知道RDB文件创建完毕

BGSAVE
创建一个子进程，由子进程负责创建RDB文件，服务器进程可以继续接收请求。
```



2.AOF(append-only-file)（增量备份）

当Redis服务器执行写命令时，将执行的写命令保存到AOF文件中。

AOF持久化功能的实现：

```text
1.命令追加
命令写入aof_buf缓冲区

2.文件写入
调用flushAppendOnlyFile函数，考虑是否要讲aof_buf缓冲区写入AOF文件中

3.文件同步
考虑是否将内存缓冲区的数据真正写入到磁盘中
```

`flushAppendOnlyFile`函数的行为由服务器配置的appendfsyn选项决定：

```text
appendfsync always     # 每次有数据修改发生时都会写入AOF文件。
appendfsync everysec   # 每秒钟同步一次，该策略为AOF的默认策略。
appendfsync no         # 从不同步。高效但是数据不会被持久化。
```

**优缺点**

```text
RDB:
优点：载入时恢复数据快、文件体积小
缺点：默认5分钟或更久生成一次，会一定程度上丢失数据(在持久化之前出现宕机)
AOF:
优点：丢失数据少(默认配置只丢失一秒的数据)
缺点：恢复数据相对较慢，文件体积大

如果同时开启了RDB和AOF持久化，服务器会有限使用AOF文件来还原数据(AOF更新频率快)
```



## 1.5 redis哨兵模式、集群模式

目的都是保证高可用。

```text
1.哨兵
由一个或多个哨兵去监听任意多个主服务以及主服务器下的所有从服务器，并在被监视的主服务器进行下线状态时，自动将下线主服务器属下的某个从服务器升级为主服务器。
下线：
1）主观下线
down-after-milliseconds 毫秒内主服务器无应答，Sentinel主观认为该主服务器下线

2）客观下线
Sentinel 节点会通过 sentinel 
is-master-down-by-addr 命令，向其它 Sentinel 节点询问对该节点的状态判断。如果超过 <quorum> 个数的节点判定 主节点 不可达，则该 Sentinel 节点会判断 主节点为客观下线。


2.集群
集群将所有数据划分为16384个槽位，每个节点负责其中一部分槽位，槽位的信息存储于每个节点中。
主从同步读写分离，类似Mysql的主从同步，Redis cluster支撑 N 个Redis master node，每个master node都可以挂载多个slave node。
```



## 1.6 redis为什么这么快

```text
1.纯内存操作
单进程单线程模型的KV数据库，每秒10w+ QPS

2.数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的

3.核心是基于非阻塞的IO多路复用机制(NIO)
I/O多路复用的特点是通过一种机制一个进程同时等待多个文件描述符。优势在于能处理更多的连接。

4.单线程避免了多线程的频繁上下文切换的问题，也不用去考虑加锁释放锁的操作，没有因为可能出现死锁而导致的性能消耗。
```



## 1.7 redis hash中某个key过大，变为string类型的大key，怎么处理，使用中如何避免出现这种问题?

大`key`带来的问题：

```text
1.集群模式在slot分片均匀情况下，会出现数据和查询倾斜情况，部分大key的Redis节点占用内存高，QPS高
2.大key相关的删除或自动过期时，会出现qps突降或突升，极端情况下，会造成主从复制异常，Redis服务阻塞无法响应请求。
```

处理方案：

```text
1.事前
-bigkeys 扫描

2.事后
lazyfree机制 在删除时只进行逻辑删除，把key释放操作放在bio单独的子线程处理中，减少删除大key对redis主线程的阻塞
```



## 1.8 数据库与缓存一致性问题。先更新数据库，再更新缓存，若更新完数据库了，还没有更新缓存，此时有请求过来了，访问到了缓存中的数据，怎么办？

此时会读到旧缓存，导致数据库与缓存不一致。解决方案：

将删除缓存、修改数据库、读取缓存等操作积压到队列里边，实现串行化。



# Zookeeper

## 2.1 Zookeeper应用场景

应用场景：

**分布式协调**

![image-20200428211913555](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200428211913555.png)

```text
1.系统A与系统B之间加了MQ，系统A怎么感知系统B是否将消息消费了，此时可以用Zookeeper
2.比如说系统A是订单系统，保存一个订单orderid=1，Zookeeper对订单[orderid=1]的node节点注册一个监听器
3.系统B完成订单的库存更新，对订单[orderid=1]的node更新他的值：finish_update，Zookeeper感知到订单[orderid=1]的node值变化成：finish_update，将信息反馈给系统A
4.系统A感知到系统B已经执行成功了
```

**分布式锁**

![image-20200428213104004](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200428213104004.png)

```text
一般采用curator来实现分布式锁，原理：
1）向zk发起请求，在一个目录(/locks/pd_1_stock)下，创建一个临时节点，也是带有自己客户端的id；
2）如果目录是空的，自己创建出来的节点就是第一个节点，那么加锁成功。如果成功则释放(节点删除)
3）如果宕机，基于zk的心跳机制，临时节点也会被删除。第二个客户端请求锁时，也创建一个节点，如果不是第一节点，那么向上一节点加一个watcher监听器。如果上一个节点被删除立马会感知到，然后在判断自己是不是第一节点，如果不是再监听上一级(公平锁实现)。完事后陷入等待，直到获取锁。
```

**注册中心（元数据、配置中心管理）**

![image-20200428213625085](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200428213625085.png)

```text
1.将服务A的注册信息保存到zk上去，服务A:[192.168.0.1,192.168.0.2,192.168.0.3]
2.Zookeeper里面会注册一个服务A的地址的监听器
3.调用者希望获取服务A的地址，从Zookeeper获取ip
```

`Kafka`中`Zookeeper`的作用：

```text
# broker
1.记录broker状态(启动给的时候就会生成broker.id文件夹)
2.控制器选举，kafka集群中有多个broker，其中有一个会被选举为控制器。控制器负责管理整个集群所有分区和副本的状态，例如某个分区的leader故障了，控制器会选举新的leader。
3.记录ISR集合
一条消息只有被 ISR 中的成员都接收到，才被视为“已同步”状态。
只有处于 ISR 集合中的副本才有资格被选举为 leader。
zookeeper记录着ISR的信息，而且是实时更新的，只要发现其中有成员不正常，马上移除。
4.node和topic注册
zookeeper 保存了所有node和topic的注册信息，可以方便的找到每个broker持有哪些 topic。
node和topic在zookeeper中是以临时节点的形式存在的，只要与zookeeper的session一关闭，他们的信息就没有了。
5.topic配置
zookeeper保存了topic相关配置，例如topic列表、每个topic的partition数量、副本的位置等

# consumer
1.注册consumer，创建临时节点
2.分区注册
kafka 的每个partition只能被消费组中的一个consumer消费，kafka必须知道所有partition与consumer的关系。
```

**HA高可用**

![image-20200428215401504](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200428215401504.png)

```text
1.worker01在zookeeper中创建临时节点active:worker01
2.worker02去zookeeper中查看发现临时节点是active:worker01，自己就什么都不干，等着，给active临时节点注册一个监听器
3.worker01宕机，worker01创建的临时节点就删除了，此时会通知woker02，会在zookeeper中创建一个同名的临时节点：active，worker02由备用切成主动
4.worker01恢复了，但是此时worker02是主动节点，此后worker01由主动变被动，监听，自己什么都不干。
```



# juc

`java.util.concurrent`并发编程中使用的工具类。

## 3.1 synchronized底层实现，加在方法上和加在同步代码块中编译后的区别、类锁、对象锁

详细版：

```text
java对象分为对象头和实例变量块，实例变量就是变量数据。
对象头包含了两块东西，一个是Mark Word（包含hashCode、锁数据、GC数据，等等），另一个是Class Metadata Address（包含了指向类的元数据的指针）。

在Mark Word中有指向这个对象实例关联的monitor地址，这个monitor实际上是c++实现的一个ObjectMonitor对象，里面包含了一个_owner指针，指向了持有锁的线程。

ObjectMonitor里还有一个entrylist，想要加锁的线程全部先进入这个entrylist等待获取机会尝试加锁，实际有机会加锁的线程，就会设置_owner指针指向自己，然后对_count计数器累加1次。

各个线程尝试竞争进行加锁，此时竞争加锁是在JDK 1.6以后优化成了基于CAS来进行加锁，理解为跟之前的Lock API的加锁机制是类似的，CAS操作，操作_count计数器，比如说将_count值尝试从0变为1
如果成功了就加锁成功了，如果失败了就加锁失败了。

释放锁，先对_count计数器递减1，如果为0就设置_owner为null，不再指向自己，代表自己彻底释放锁。

如果获取锁的线程执行wait，就会将计数器递减，同时_owner设置为null，然后自己进入waitset中等待唤醒，别人获取了锁执行notify的时候就会唤醒waitset中的线程竞争尝试获取锁

synchronized ObjectMonitor  ==  ReentrantLock AQS
```

简略版：

底层：jvm指令：monitorenter  monitorexit

monitor可以重复对一个对象加锁，计数器加1

释放锁，计数器减1，计数器成0后，别的线程可以对该对象进行加锁。

![image-20200225214541138](/Users/tulingfeng/Library/Application%20Support/typora-user-images/image-20200225214541138.png)

加载方法和加载同步代码块上在锁粒度上存在不同。

类锁：用于类的静态方法或者一个类的`class`对象上

对象锁：用于对象实例方法或者一个对象实例上



## 3.2 锁升级的过程

无锁 --> 偏向锁 --> 轻量级锁 --> 自旋锁 --> 重量级锁

1.锁消除

JIT编译器对synchronized锁做的优化，在编译时，JIT会通过逃逸技术，来分析synchronized锁对象，是不是只可能被一个线程来加锁，没有其他线程来竞争锁，这个时候编译就不用加入monitorenter和monitorexit的指令。

仅仅一个线程争用锁的时候，可以消除这个锁。



2.偏向锁

monitorenter和monitorexit是要使用CAS操作加锁和释放锁的，开销较大，如果发现大概率只有一个线程会主要竞争一个锁，那么给这个锁维护一个偏好（Bias），后面他加锁和释放锁，基于Bias来执行，不需要通过CAS。

性能会提升很多。

如果有其他的线程来竞争这个锁，此时就会收回之前那个线程分配的那个Bias偏好。



3.轻量级锁

如果偏向锁没能成功实现，就是因为不同线程竞争太频繁了，此时就会采用轻量级锁的方式来加锁。

将对象头的Mark Word里有一个轻量级锁指针，尝试指向持有锁的线程，然后判断一下是不是自己加的锁。

如果是自己加的锁，那就执行代码；如果不是自己加的锁，那就是加锁失败，说明其他人加了锁，此时就升级为重量级锁。



4.适应性锁

如果线程持有锁的时间很短，那么一个线程竞争锁不到，就会暂停，发生上下文切换，让其他线程来执行。频繁切换上下文的话，会导致开销过大。

此时可以采用忙等策略，自旋等待获取锁。

如果一个线程持有锁的时间过长，那么其他线程获取不到锁，就会暂停，发生上下文切换，让其他线程来执行，这种自己暂停获取锁的方式，就是所谓的重量级锁。

根据不同情况自动调整的过程，就是适应性锁。



## 3.3 对CAS的理解，CAS带来的问题，如何解决这些问题

`Compare-And-Swap` 是一条CPU并发原语。

底层：`Unsafe` 类+⾃旋锁

`Unsafe` 类是`CAS` 的核⼼类，通过这个后⻔，可以直接操作特定内存的数据。

自旋锁通过的是`compareAndSwapInt`方法。

**CAS带来的问题**

```text
1.CAS失败，会⼀直尝试⾃旋，如果长时间⼀直不成功，可能会给CPU带来很大的开销；
2.只能保证一个共享变量的原⼦操作
3.ABA
线程1从内存位置V中取出A，此时另⼀个线程2也从内存中取出A，并且线程2进行了一些操作值变成了
B，接着⼜将V位置的数据变成A,这时候线程1进⾏CAS操作发现内存中仍然是A，线程1操作成功。
```

**解决方案**

```text
1.自旋设置时间或者retry次数
2.只保证一个共享变量的原子操作
可以引入AtomicRefrence，内部添加类
3.ABA 加版本号，AtomicStampedReference 带时间戳的AtomicRefrence
```



## 3.4 volatile底层、synchronized底层、锁升级的过程、MESI协议

`volatile`能保证有序、可见性，都是通过内存屏障来做的。

有序性 --> `Release/Store屏障`

可见性--> `Load屏障`

```text
线程1：
Release屏障
isRunning = false;
Store屏障 

线程2：
Load屏障
while(isRunning) {
    Acquire屏障
    // 代码逻辑
}

在volatile变量写操作的前面会加入一个release屏障，然后在之后会加入一个Store屏障，这样就可以保证volatile的任何读写操作都不会指令重排。
Store屏障保证了写完数据之后，立马会执行flush处理器缓存的操作。

在volatile变量读操作的前面会加入一个Load屏障，这样就可以保证对这个变量的读取时，如果被别的处理器修改过了，必须得从其他处理器的高速缓存(或者主内存)中加载自己本地高速缓存里，保证读到的是最新数据。
```

`volatile`不能保证原子性，一般要通过`synchronized`关键字或原子类`AutomicInteger`来做。

**MESI协议**

缓存一致性协议。

```text
M:Modified
E:Exclusive
S:Shared
I:Invalid
```

MESI协议规定：对一个共享变量的读操作可以是多个处理器并发执行的，但是如果是对一个共享变量的写操作，只有一个处理器可以执行，其实也会通过排他锁的机制保证就一个处理器能写。

之前说过那个cache entry的flag代表了缓存数据的状态，MESI协议中划分为：

```text
（1）invalid：无效的，标记为I，这个意思就是当前cache entry无效，里面的数据不能使用

（2）shared：共享的，标记为S，这个意思是当前cache entry有效，而且里面的数据在各个处理器中都有各自的副本，但是这些副本的值跟主内存的值是一样的，各个处理器就是并发的在读而已

（3）exclusive：独占的，标记为E，这个意思就是当前处理器对这个数据独占了，只有他可以有这个副本，其他的处理器都不能包含这个副本

（4）modified：修改过的，标记为M，只能有一个处理器对共享数据更新，所以只有更新数据的处理器的cache entry，才是exclusive状态，表明当前线程更新了这个数据，这个副本的数据跟主内存是不一样的
```

MESI协议规定了一组消息，就说各个处理器在操作内存数据的时候，都会往总线发送消息，而且各个处理器还会不停的从总线嗅探最新的消息，通过这个总线的消息传递来保证各个处理器的协作。

![image-20200402221831356](/Users/tulingfeng/Library/Application%20Support/typora-user-images/image-20200402221831356.png)

**工作原理**

```text
1.处理器0读取某个变量的数据时，首先会根据index，tag和offset从高速缓存的拉链链表中读取数据，如果发现状态为I，也就是无效的，此时就会发送read消息到总线
2.主内存会返回对应的数据给处理器0，处理器0就会把数据放到高速缓存里，同时cache entry的flag状态是S
3.处理器0对一个数据进行更新的时候，如果数据状态是S，则此时就需要发送一个invalidate消息到总线，尝试让其他的处理器的高速缓存的cache entry全部变为I，以获得数据的独占锁
4.其他的处理器1从总线嗅探到invalidate消息，此时就会把自己的cache entry设置为I，也就是过期掉自己本地的缓存，然后就是返回invalidate ack消息到总线，传递回处理器0，处理器0必须受到所有处理器返回的ack消息
5.处理器0就会将cache entry先设置为E，独占这条消息，在独占期间，别的处理器不能修改数据
6.处理器0修改这条数据，接着讲数据设置为M，也有可能把数据强制写回主内存，具体看底层硬件的实现。
7.然后其他处理器此时这条数据的状态都是I了，那如果要读的话，那如果要读的话，全部都需要重新发送read消息，从主内存（或者是其他处理器）来加载，这个具体怎么实现要看底层的硬件了。
```



## 3.5 aqs

核心数据结构：双向链表+state(锁状态)

底层操作：`CAS`

![image-20200418232557001](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200418232557001.png)

`AQS`定义了两种资源共享方式：

`Exclusive`(独占，只有一个线程能执行，如`Reentrantlock`)

`Share`(共享，多个线程可同时执行，如`Semaphore/CountDownLatch`)

**Reentrantlock实现**

`tryAcquire-tryRelease`，独占方式获取、释放资源。

图示：

![image-20200225225121460](/Users/tulingfeng/Library/Application%20Support/typora-user-images/image-20200225225121460.png)

步骤：

```text
1.AQS中初始state=0，线程1、2会使用tryAcquire()方法去尝试更新state= 1，采用的是CAS策略，只有一个线程（线程1）能更新state=1，加锁成功，更新加锁线程为线程1，

2.此时线程2加锁失败，线程2进入等待队列，挂起。

3.线程1执行完代码，会将state=0，加锁线程为null，释放锁。同时会去唤醒等待队列中的头线程。

4.线程2会去更新state=1,加锁成功，执行相应代码。
```

非公平锁：

如果在线程1释放锁唤醒线程2加锁之前，线程3立即执行CAS策略，更新state=1，加锁成功。线程2进去之后加锁依旧失败。

公平锁：

线程3进入队列进行排队，先执行线程2。

注意：释放锁之前，线程1自己是可以重复获取此锁的(`state`会累加)



## 3.6 countDownLatch如何实现

是基于`AQS`的`Share`模式来做的。`tryAcquireShared-tryReleaseShared`，共享方式获取、释放资源。

具体步骤：

```text
1.任务分为N个子线程去执行，state初始化为N
2.这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会减1
3.等待所有子线程都执行完后即state=0，会unpark()主调用线程
4.主调用线程就会从await()函数返回，继续如下动作
```



## 3.7 hashMap、concurrentHashMap的区别及底层实现、hashMap和hashTable 的区别

`hashMap`与`concurrentHashMap`区别：

```text
1.底层数据结构
hashMap底层由：数组+链表或数组+红黑树(数组长度大于64，链表长度大于8)
concurrentHashMap底层：1.8以前是由Segment数组结构和HashEntry数组结构组成，依旧是数据+链表
1.8以后使用Node存放数据，没有采用Segment分段

2.线程是否安全
hashMap线程不安全(rehash、put操作)：
1）多线程扩容，引起链表死循环：多线程环境下，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，
2）多线程put时，导致元素丢失。或者put非null元素，但get出来却是null流程。

concurrentHashMap是线程安全的
1.8以前用的是Segment分段锁技术，其中Segment继承于ReentrantLock
1.8以后采用的是CAS+synchronized
1) 同一元素同时put执行CAS
同一个时间，只有一个线程能成功执行这个CAS，就是说他刚开始先获取一下数组[5]这个位置的值，null，然后执行CAS，线程1，比较一下，put进去我的这条数据，同时间，其他的线程执行CAS，都会失败。
 
2) 不同元素执行put可以并发执行，但是如果存在失败的线程，就需要在这个位置使用synchronized对node加锁处理了。
```

`ConcurrentHashMap`是如何解决`HashMap`并发问题

```text
1.首先new一个新的hash表(nextTable)出来，大小是原来的2倍。后面的rehash都是针对这个新的hash表操作，不涉及原hash表(table)。

2.然后会对原hash表(table)中的每个链表进行rehash，此时会尝试获取头节点的锁。这一步就保证了在rehash的过程中不能对这个链表执行put操作。

3.通过sizeCtl控制，使扩容过程中不会new出多个新hash表来。

4.最后，将所有键值对重新rehash到新表(nextTable)中后，用nextTable将table替换。这就避免了HashMap中get和扩容并发时，可能get到null的问题。

5.在整个过程中，共享变量的存储和读取全部通过volatile或CAS的方式，保证了线程安全。
```

`hashMap`与`hashTable`区别：

```text
1.hashmap是线程不安全的，hashtable是线程安全的
hashtable对数据操作的时候都加锁，虽然线程安全但是效率低

2.hashmap键值都可以为null，hashtable键或值不允许为null
hashtable在put空值时就直接抛出空指针异常，使用的是安全失败机制(fail-fast)
hashmap做了特殊处理：
key==null ? 0:xx

3.实现方式不同：
hashtable继承了Dictionary类，而HashMap继承得是AbstractMap类

4.初始化容量不同：
HashMap的初始容量为16，HashTable初始容量为：11，负载因子都是0.75

5.扩容机制不同：
当现有容量大于总容量*负载因子时，HashMap扩容规则为当前容量翻倍，HashTable扩容规则为当前容量翻倍+1

6.迭代器不同：
hashmap中的iterator的迭代器是fail-fast的，而hashtable的enumerator不是fail-fast的
```



**fail-fast(快速失败)与fail-safe(安全失败)**

```text
1.fail-fast

在使用迭代器对集合对象进行遍历的时候，如果 A 线程正在对集合进行遍历，此时 B 线程对集合进行修改（增加、删除、修改），或者 A 线程在遍历过程中对集合进行修改，都会导致 A 线程抛出 ConcurrentModificationException 异常。

原因：
迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变 modCount 的值。

每当迭代器使用 hashNext()/next() 遍历下一个元素之前，都会检测 modCount 变量是否为 expectedModCount 值，是的话就返回遍历；否则抛出异常，终止遍历。

2.fail-safe

采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。
由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，故不会抛 ConcurrentModificationException 异常。

java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。
```



## 3.8 对线程池的理解，在项目中如何使用的，多个线程之间如何共享数据，多个进程之间如何共享数据

线程池的作用：

```text
1.线程复⽤
降低资源消耗
2.控制最⼤并发数
提⾼响应速度
3.管理线程
提⾼线程的可管理性，使⽤线程池可以进行统一的分配，调优和监控
```

一般使用的方式：

```text
Executor/Executors/ThreadPoolExecutor
```

推荐使用`ThreadPoolExecutor`

`ThreadPoolExecutor`源码：

```java
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.acc = System.getSecurityManager() == null ?
                null :
                AccessController.getContext();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }

# 七大参数
corePoolSize: 线程池中的常驻核心线程数
maximumPoolSize: 线程池能够容纳同时执行的最大线程数
keepAliveTime: 多余的空闲线程的存活时间，当前线程池数量超过corePoolSize时，空闲时间达到keepAliveTime值时，多余空闲线程会被销毁直到只剩下corePoolSize个线程为止。
unit:keepAliveTime单位
workQueue: 任务队列，被提交但尚未被执行的任务
threadFactory: 表示生成线程池中工作线程的线程工厂，用于创建线程一般用默认即可
handler: 拒绝策略，表示当队列满了并且工作线程大于等于线程池的最大线程数时，如果来拒绝请求执行的runnable策略。

# 拒绝策略
1.AbortPolicy(默认)
直接抛出RejectedExecutionException异常组织系统正常运行
2.CallerRunPolicy
调用者运行一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退给调用者，降低流量
谁让你来找我的就退回让你再去找谁
3.DiscardOldestPolicy
抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务
4.DiscardPolicy
直接丢弃任务，不予任何处理也不抛出异常。如果允许任务丢失，这是最好的一种方案

都集成了RejectedExecutionHandler 接口
```

**多个线程之间如何共享数据，多个进程之间如何共享数据**

```text
线程间共享数据：volatile关键字，创建一个Runnable，里面包含共享数据

进程间共享数据：共享内存，fork子进程 文件偏移量可以共享
```



## 3.9 什么是红黑树，什么是b-tree，为什么hashMap中用红黑树不用其他树

红黑树：

```text
性质：
1.所有的节点都是黑色或者红色
2.根节点是黑色
3.每个叶子节点都是黑色的空节点
4.每个红色节点的两个子节点都是黑色
5.从任意节点到其子节点的所有路径都经过相同的黑色节点
```

`B树`

节点存有`data`

**为什么hashMap中用红黑树不用其他树?**

`AVL、B、B+`树都比较适合查找密集型任务。

`hashMap`插入修改操作更多一些，此时比较适合使用红黑树，更容易平衡和调试。



# 线上问题

## 4.1 有没有排查过线上oom的问题，如何排查的？

一般出现`oom`的位置：栈、堆、元数据区（`Metaspace`）

```text
1.栈溢出 java.lang.StackOverflowError
栈溢出，⽅法存在栈中，递归调⽤即可导致栈溢出。
2.堆溢出 java.lang.OutofMemoryError:Java Heap space
堆中存对象没有被垃圾回收，一直累积直到出现OOM
3.元数据区溢出 java.lang.OutofMemoryError: Metaspace
动态代理类一直创建没有被销毁
```

`jvm`参数：

```text
-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=/usr/local/app/oom
```

查看`dump`文件。使用`jmap`去分析:

```text
jamp -dump:format=b,file=/homr/test/oom/hprof pid
```

查看垃圾回收实时状态

```text
jstat -gc PID 1000(每秒1次输出1000次)
```



## 4.2 假设有下图所示的一个full gc 的图，纵向是内存使用情况，横向是时间，你如何排查这个full gc的问题，怎么去解决你说出来的这些问题

![image-20200419084113462](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200419084113462.png)



登录到对应机器查看`GC log`。分析`GC log`。

使用`jstat -gc pid 1000`查看实时`GC`情况。

使用`jmap -dump:format=b,file=temp.dump pid`dump文件，但是这个过程可能也会出现`OOM`。



按照图示：应该是老年代对象不断累积，触发了空间阈值`-XX:CMSInitiatingOccupancyFraction`。

解决方案：

```text
1.如果阈值太小，可以适当提高阈值
2.查看JVM新生代、老年代，适当提高Survivor区大小，让Young GC后的存活对象尽量少的进入老年代。
```

**如果每次full gc后，内存不在统一水平线上，而是成水平上升直线**

说明可能存在垃圾回收不掉，内存出现泄露问题。此时一般的套路是：

```text
1.开启jvm打印dump文件的参数
2.使用jmap分析dump文件，查看相关代码
```

注：老年代触发`Full GC`的条件：

```text
a）Young GC之前触发Full GC：新生代所有对象大于老年代剩余内存，未设置空间担保或空间担保失败(老年代可用内存小于历次新生代GC后进入老年代的平均对象大小)
b）Young GC后的存活对象大于Survivor区可用内存，就会直接进入老年代，此时老年代内存不足
c）设置了-XX:CMSInitiatingOccupancyFraction=92，前面都没满足，刚好这个条件满足了，老年代内存使用率超过了92%，此时就会自行触发Full GC。
```



## 4.3 查看CPU过高的定位思路

```text
1.top命令 找到cpu占比最高
2.ps -ef | grep pid 或 jps -l 是哪个后台程序给我们惹事
3.top -Hp pid 找到具体线程
4.将线程id转换成16进制格式小写英文 tid
5.打印堆栈信息
jstack pid |grep tid -A 30  # A 30表示打印30行数据
```



## 4.4 线上日志分析步骤总结

进行线上日志分析主要有如下步骤：

```text
1.通过 top命令查看CPU情况，如果CPU比较高，则通过 top-Hp命令查看当前进程的各个线程运行情况，找出CPU过高的线程之后，将其线程id转换为十六进制的表现形式，然后在jstack日志中查看该线程主要在进行的工作。这里又分为两种情况：
1）如果是正常用户线程，可以通过该线程的堆栈信息查看其具体是在哪处用户代码处运行比较消耗CPU
2）如果该线程是VMThread(指的是垃圾回收线程)，使用jstack -gc监控当前系统的GC状况
然后通过 jmapdump:format=b,file=导出系统当前的内存数据。导出之后将内存情况放到eclipse的mat工具中进行分析即可得出内存中主要是什么对象比较消耗内存，进而可以处理相关代码；

2.如果通过top命令查看到CPU并不高，并且系统内存占有率也比较低，此时可以考虑是否由于如下几种状况造成的：
1）如果是接口调用比较耗时，并且是不定时出现，则可以通过压测的方式加大阻塞点出现的频率，从而通过 jstack查看堆栈信息，找到阻塞点；
2）如果是某个功能突然出现停滞的状况，这种情况也无法复现，此时可以通过多次导出 jstack日志的方式对比哪些用户线程是一直都处于等待状态，这些线程就是可能存在问题的线程（比如说CountDownLatch 线程挂掉，主线程一直在等待）；
3）如果通过 jstack可以查看到死锁状态，则可以检查产生死锁的两个线程的具体阻塞点，从而处理相应的问题。
```





# 项目经验

## 5.1 聊一聊对分库分表的理解

分库分表的原因：

```text
分库(水平扩展，加机器)
1.写并发单机(1000多QPS)扛不住
2.磁盘容量扛不住

分表
1.单表数据量太大，sql语句查询太慢
```

**分库：**

水平分库：

采用多个数据库，每个库中的表和表结构都是一样的。插入时根据主键hash写入不同的数据库

每个库中还可以拆分成多张表，表结构都是一样的。

```text
range分发：根据时间划分。
好处：容易扩容，比如给每个月都增加一个库就可以了。
缺点：用户大部分都是操作最新数据，所以当天的请求最终都是打到一个数据库了。无法分发请求压力。使用range
分发要看具体的场景，比如用户一般都是均匀访问现在和历史的数据。

hash分发：根据唯一id进行hash。（常用）
好处：平均分配了每个库的请求压力。
缺点：扩容比较麻烦，需要将原来数据库的数据导入到新的数据库，涉及数据迁移的过程。
```

垂直分库：

其实就是业务不同，直连的数据库不同。

**分表：**

水平分表：

数据库中表可以拆分成多张表，表结构是一样的。

垂直分表：

将一张表的多个字段进行拆分。表1（id + 5个常用字段），表2（id + 10个不常用字段）等等

```text
为什么要垂直拆分?
1.数据库本身也是有缓存的，高频数据的行字段越少，就能缓存更多的数据(缓存页)；
2.行字段太多会导致数据单表的数据量很大，SQL性能变差。
```



## 5.2 数据库迁移

1.停机迁移

发布公告，“今天0点到6点系统维护，不能访问”。

然后将数据读取，在通过数据库中间件，写入新的数据库。修改新代码的数据库配置。ok。

```text
缺点：
1.必须停机
2.如果5点还没搞定，先回滚。第二天再搞
```

2.不停机双写迁移方案

```text
1.双写数据库。修改系统A的代码，将所有增删改的操作，都加上对新库的增删改。(部分字段的更新操作，需要从老库读
取整行，写入新库)
2.后台数据迁移。比较老库和新库的数据更新时间戳或者新库没有，就写入数据库中间件，导入新库。（不能将老库的旧
数据覆盖掉新库的新数据）
3.数据检查。理论上，操作结束后，老库和新库的数据应该是一样的。如果有不同的，需要再确认是否导入新库。
迁移+检查，可能整个过程需要跑好几天。
```

![image-20200429151841876](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200429151841876.png)



## 5.3 分库分表的动态扩容方案

```text
为什么需要扩容？
1.写并发不够。每台数据库服务器的写并发最多2000/s，4台就是8000/s.
2.数据库磁盘容量不够了。
```

一般32库*32表就可以。1024张表，假设每个表放入500万数据，那`MySQL`能存50亿条数据。

部署4台机器，每台机器上8个库，每个库32张表。

现在需要扩容一倍。（也可以加到32台服务器，每台服务器1个库32张表）

```text
方案：
1.再申请4台机器，将原来ABCD服务器上的数据库，每台都迁移4个库到A1、B1、C1、D1服务器上。
2.现在8台机器，每台4个库32张表。写并发提升一倍，磁盘使用减少一半。
3.服务端修改下配置就好了。
优点：
不用自己做数据迁移。直接由dba做库和表的迁移工作。
只有修改数据库服务器的数量，不用修改库和表的数目。
路由规则也不用改变。库num = id % 32，表num = id / 32 % 32
```



## 5.4 mysql读写分离

```text
为什么要读写分离？
1.mysql是半双工的，同一时刻只能读或者写
2.即使采用了缓存，读请求还是有一些无法命中缓存，加上写请求。数据库还是可能处理很高的请求。
```

![image-20200429164059449](/Users/tulingfeng/Library/Application Support/typora-user-images/image-20200429164059449.png)

注意：IO线程从库拉取binlog日志，以前是单线程，5.6.x之后可以多线程。但是从库的sql线程执行relay日志还是单线程。它是性能瓶颈。（写并发1000/s 从库延时几ms，写并发2000/s 从库延时几十ms，写并发4000/s从库延迟可能有几秒）



`binlog vs redo log`

```text
1.binlog 归档日志，里面记录偏向于逻辑性的日志，类似于：对users表中的id=10的一行数据做了更新操作，更新以后的值是什么
redo log记录的是偏向物理性质的重做日志，类似于：对哪个数据页中的什么记录，做了个什么修改

2.binlog不是InnoDB存储引擎特有的日志文件，是属于mysql server自己的日志文件
redo log是属于InnoDB存储引擎特有的一个东西
```



## 5.5 MySQL主从延时问题

```text
1.写并发太高，导致读库同步数据慢。（写完就查这条）
2.写少，读太多了。（从库一直在被范围查询）
```

`show status` -- > `seconds_behind_master`，可以查看延时。

解决方案：

```text
1.分库。
将主库拆分为4个库，原来2000/s的写并发几十ms的延时，现在每个库500/s的写并发就几ms的延时了
2.打开mysql的并行复制。
但是：意义不是很大。因为并行复制是库级别的多线程，往往出现这种情况就是由于
某个库写并发太高
3.重写代码逻辑。
比如上述案例step2的查询时没有必要的，插入后直接更新就可以避免。
4.设置直连主库。
对于数据实时性要求较高的根本做法还是去读主库,因为主库的数据才会没有延迟的问题。
```

## 5.6 MySQL主从复制数据丢失问题，以及半同步复制的原理

一般的主从复制，如果主库宕机，数据还没同步到从库，此时就会有数据丢失。

解决方案，一般是用半同步复制：

```text
1.主库写入binlog，强制立即将binlog同步到从库
2.从库将日志写入本地的relay日志后，会给主库返回一个ack
3.主库至少收到一个从库的ack，才认为写操作完成了
```



## 5.7 并行复制

从库开启读个线程，并行从relay日志读取不同库的日志，并行地执行数据库的更新操作。

注意：这个库级别的并行，不同的库不同的线程，同一个库还是一个线程。



